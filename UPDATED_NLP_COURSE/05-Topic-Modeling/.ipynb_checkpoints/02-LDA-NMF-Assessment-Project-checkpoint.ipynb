{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic Modeling Assessment Project\n",
    "\n",
    "Welcome to your Topic Modeling Assessment! For this project you will be working with a dataset of over 400,000 quora questions that have no labeled cateogry, and attempting to find 20 cateogries to assign these questions to. The .csv file of these text questions can be found underneath the Topic-Modeling folder.\n",
    "\n",
    "Remember you can always check the solutions notebook and video lecture for any questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task: Import pandas and read in the quora_questions.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Question\n",
      "0  What is the step by step guide to invest in sh...\n",
      "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
      "2  How can I increase the speed of my internet co...\n",
      "3  Why am I mentally very lonely? How can I solve...\n",
      "4  Which one dissolve in water quikly sugar, salt...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(404289, 1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "npr = pd.read_csv('quora_questions.csv')\n",
    "print(npr.head())\n",
    "npr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 32971)\t2\n",
      "  (0, 15464)\t1\n",
      "  (0, 18192)\t1\n",
      "  (0, 31209)\t1\n",
      "  (0, 21408)\t1\n",
      "  (0, 17507)\t1\n",
      "(404289, 38669)\n",
      "38669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = cv.fit_transform(npr['Question'])\n",
    "print(dtm[0])\n",
    "print(dtm.shape)\n",
    "print(len(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term: step, Count: 2\n",
      "Term: guide, Count: 1\n",
      "Term: invest, Count: 1\n",
      "Term: share, Count: 1\n",
      "Term: market, Count: 1\n",
      "Term: india, Count: 1\n"
     ]
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names()\n",
    "non_zero_counts = dtm[0]\n",
    "\n",
    "# Iterate through the non-zero entries and print the terms and their counts\n",
    "for col_index in non_zero_counts.indices:\n",
    "    term = feature_names[col_index]\n",
    "    count = non_zero_counts[0, col_index]\n",
    "    print(f\"Term: {term}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "LDA = LatentDirichletAllocation(n_components=7,random_state=42)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "38669\n",
      "[[1.43027512e-01 1.81171965e-01 1.46422411e-01 5.14254964e+00\n",
      "  1.72316092e+00]\n",
      " [1.43597885e-01 6.86689433e+01 1.42857928e-01 1.42857314e-01\n",
      "  1.42857667e-01]\n",
      " [5.30622659e+00 1.50086747e-01 1.42857911e-01 1.42857311e-01\n",
      "  1.42857660e-01]\n",
      " [1.43676091e+01 7.53570572e+02 1.42857822e-01 1.43026583e-01\n",
      "  1.42857604e-01]\n",
      " [1.43251681e-01 1.43133965e-01 1.42857771e-01 1.42994613e-01\n",
      "  1.43458562e-01]\n",
      " [2.47595566e-01 1.42937359e-01 2.13928835e+00 1.42857249e-01\n",
      "  5.60978550e-01]\n",
      " [2.66486917e+01 1.43154531e-01 1.42857806e-01 1.42857290e-01\n",
      "  1.43829037e-01]]\n",
      "(7, 38669)\n",
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['best', 'india', 'phone', 'use', 'good', 'does', 'engineering', 'android', 'app', 'google', 'software', 'mobile', 'using', 'company', 'free']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['best', 'money', 'learn', 'way', 'make', 'english', '500', 'online', 'notes', '1000', 'improve', 'language', 'stop', 'programming', 'ways']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['life', 'does', 'time', 'good', 'best', 'books', 'india', 'energy', 'average', 'travel', 'compare', 'did', 'water', 'book', 'safe']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['quora', 'people', 'new', 'know', 'best', 'questions', 'things', 'year', 'movie', 'old', 'question', 'does', 'thing', 'movies', 'make']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['account', 'facebook', 'difference', 'does', 'job', 'india', 'increase', 'instagram', 'number', 'car', 'password', 'rid', 'differences', 'email', 'country']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['does', 'like', 'did', 'trump', 'world', 'people', 'mean', 'think', 'love', 'feel', 'india', 'donald', 'long', 'sex', 'girl']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['best', 'start', 'weight', 'good', 'lose', 'prepare', 'learning', 'live', 'way', 'school', 'study', 'science', 'exam', 'days', 'business']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(LDA.components_))\n",
    "print(len(LDA.components_[0]))\n",
    "print(LDA.components_[:, :5])  \n",
    "print(LDA.components_.shape)\n",
    "for index, topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[::-1][:15]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "#### Task: Use TF-IDF Vectorization to create a vectorized document term matrix. You may want to explore the max_df and min_df parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17507)\t0.19115261267972286\n",
      "  (0, 21408)\t0.3003349492828469\n",
      "  (0, 31209)\t0.3291744678610915\n",
      "  (0, 18192)\t0.31649207559225107\n",
      "  (0, 15464)\t0.3894800676252344\n",
      "  (0, 32971)\t0.7162693694576815\n",
      "(404289, 38669)\n",
      "38669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm2 = tfidf.fit_transform(npr['Question'])\n",
    "print(dtm2[0])\n",
    "print(dtm2.shape)\n",
    "print(len(tfidf.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13568)\t0.19115261267972286\n",
      "  (0, 16555)\t0.3003349492828469\n",
      "  (0, 24181)\t0.3291744678610915\n",
      "  (0, 14125)\t0.31649207559225107\n",
      "  (0, 11995)\t0.3894800676252344\n",
      "  (0, 25551)\t0.7162693694576815\n",
      "(404289, 29917)\n",
      "29917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf2 = TfidfVectorizer(max_df=0.9, min_df=3, stop_words='english')\n",
    "dtm3 = tfidf2.fit_transform(npr['Question'])\n",
    "print(dtm3[0])\n",
    "print(dtm3.shape)\n",
    "print(len(tfidf2.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<404289x38669 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2002912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization\n",
    "\n",
    "#### TASK: Using Scikit-Learn create an instance of NMF with 20 expected components. (Use random_state=42).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:315: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  \"'nndsvda' in 1.1 (renaming of 0.26).\"), FutureWarning)\n",
      "C:\\Users\\Max\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1091: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=20, random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "nmf_model = NMF(n_components=20,random_state=42)\n",
    "nmf_model.fit(dtm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 38669)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['best', 'movies', 'book', 'books', '2016', 'ways', 'movie', 'laptop', 'buy', 'phone', 'places', 'visit', 'place', 'read', 'thing']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['does', 'mean', 'work', 'feel', 'long', 'cost', 'compare', 'really', 'exist', 'use', 'differ', 'looking', 'sex', 'recruit', 'majors']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['quora', 'questions', 'question', 'ask', 'answer', 'answers', 'google', 'asked', 'delete', 'improvement', 'easily', 'post', 'needing', 'answered', 'add']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['money', 'make', 'online', 'earn', 'ways', 'youtube', 'easy', 'home', 'free', 'internet', 'black', 'friends', 'investment', 'website', 'using']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['life', 'purpose', 'meaning', 'thing', 'important', 'real', 'moment', 'change', 'want', 'live', 'changed', 'death', 'day', 'earth', 'balance']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['india', 'pakistan', 'war', 'spotify', 'job', 'available', 'olympics', 'country', 'business', 'china', 'company', 'president', 'minister', 'engineering', 'reservation']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['learn', 'programming', 'language', 'start', 'learning', 'java', 'languages', 'python', 'want', 'hacking', 'did', 'book', 'english', 'online', 'beginners']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['trump', 'donald', 'clinton', 'president', 'hillary', 'win', 'did', 'election', 'better', 'vote', '2016', 'presidential', 'think', 'presidency', 'happen']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['world', 'war', 'did', 'start', 'iii', 'country', 'end', 'happen', 'pakistan', 'place', 'countries', 'coming', 'win', 'business', 'russia']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['like', 'feel', 'sex', 'look', 'girl', 'live', 'girls', 'work', 'women', 'culture', 'men', 'guy', 'don', 'companies', 'indian']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #10\n",
      "['good', 'books', 'bad', 'ways', 'engineering', 'work', 'job', 'start', 'read', 'business', 'songs', 'movies', 'positions', 'departments', 'ca']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #11\n",
      "['500', 'notes', '1000', 'rs', 'rupee', 'indian', 'black', 'banning', 'ban', 'government', 'think', 'economy', 'currency', 'modi', 'money']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #12\n",
      "['know', 'new', 'things', 'day', 'going', 'employees', 'don', 'year', '2017', 'girl', 'likes', 'mind', 'resolution', 'resolutions', 'blowing']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #13\n",
      "['english', 'improve', 'skills', 'writing', 'speaking', 'pronunciation', 'communication', 'speak', 'fluently', 'language', 'ways', 'spoken', 'skill', 'fluent', 'aspects']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #14\n",
      "['weight', 'lose', 'gain', 'ways', 'fat', 'fast', 'loss', 'quickly', 'reduce', 'pounds', 'month', 'exercise', 'healthy', 'help', 'diet']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #15\n",
      "['time', 'travel', 'possible', 'sex', 'home', 'job', 'favorite', 'movies', 'machine', 'person', 'did', 'spend', 'long', 'feel', 'having']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #16\n",
      "['love', 'fall', 'girl', 'person', 'know', 'true', 'friend', 'really', 'forget', 'tell', 'feel', 'girlfriend', 'did', 'make', 'marriage']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #17\n",
      "['way', 'easiest', 'suicide', 'fastest', 'commit', 'best', 'account', 'instagram', 'painless', 'increase', 'facebook', 'quickest', 'prepare', 'hack', 'easy']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #18\n",
      "['difference', 'engineering', 'computer', 'science', 'software', 'data', 'account', 'use', 'job', 'better', 'mechanical', 'phone', 'scripting', 'java', 'web']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #19\n",
      "['people', 'think', 'don', 'ask', 'believe', 'hate', 'questions', 'flat', 'google', 'mind', 'easily', 'use', 'stop', 'blowing', 'earth']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[::-1][:15]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404289, 20)\n",
      "                                             Question  Topic\n",
      "0   What is the step by step guide to invest in sh...      5\n",
      "1   What is the story of Kohinoor (Koh-i-Noor) Dia...     16\n",
      "2   How can I increase the speed of my internet co...     17\n",
      "3   Why am I mentally very lonely? How can I solve...     11\n",
      "4   Which one dissolve in water quikly sugar, salt...     14\n",
      "5   Astrology: I am a Capricorn Sun Cap moon and c...      1\n",
      "6                                 Should I buy tiago?      0\n",
      "7                      How can I be a good geologist?     10\n",
      "8                     When do you use シ instead of し?     19\n",
      "9   Motorola (company): Can I hack my Charter Moto...     17\n",
      "10  Method to find separation of slits using fresn...      2\n",
      "11        How do I read and find my YouTube comments?      3\n",
      "12               What can make Physics easy to learn?      3\n",
      "13        What was your first sexual experience like?      9\n",
      "14  What are the laws to change your status from a...      1\n",
      "15  What would a Trump presidency mean for current...      7\n",
      "16                       What does manipulation mean?      1\n",
      "17  Why do girls want to be friends with the guy t...      9\n",
      "18  Why are so many Quora users posting questions ...      2\n",
      "19  Which is the best digital marketing institutio...      0\n"
     ]
    }
   ],
   "source": [
    "topic_results = nmf_model.transform(dtm2)\n",
    "print(topic_results.shape)\n",
    "npr2 = npr\n",
    "npr2['Topic'] = topic_results.argmax(axis=1)\n",
    "print(npr.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['best', 'book', 'books', 'ways', 'movies', 'buy', 'laptop', '2016', 'places', 'visit', 'place', 'online', 'phone', 'movie', 'coaching']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['does', 'mean', 'work', 'feel', 'compare', 'long', 'cost', 'differ', 'really', 'looking', 'universities', 'recruit', 'use', 'grads', 'majors']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['india', 'pakistan', 'war', 'china', 'country', 'spotify', 'available', 'job', 'olympics', 'buy', 'company', 'business', 'start', 'world', 'engineering']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['people', 'think', 'don', 'ask', 'questions', 'believe', 'world', 'mind', 'easily', 'hate', 'google', 'blowing', 'use', 'say', 'white']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['500', 'notes', '1000', 'rs', 'indian', 'rupee', 'black', 'banning', 'ban', 'government', 'think', '2000', 'currency', 'modi', 'economy']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['like', 'feel', 'look', 'culture', 'companies', 'work', 'different', 'girl', 'sex', 'live', 'girls', 'women', 'don', 'world', 'corporate']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['good', 'work', 'books', 'bad', 'ways', 'near', 'solar', 'provider', 'engineering', 'panel', 'installation', 'ca', 'california', 'balance', 'differ']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['make', 'money', 'friends', 'month', 'better', 'want', 'use', 'app', '000', 'love', 'possible', 'using', 'android', 'youtube', 'website']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['did', 'battle', 'compare', 'world', 'war', 'movie', 'significance', 'contrast', 'start', 'somme', 'win', 'really', 'come', '2016', 'die']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['quora', 'questions', 'question', 'ask', 'answers', 'google', 'answer', 'improvement', 'easily', 'asked', 'needing', 'answered', 'use', 'search', 'delete']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #10\n",
      "['know', 'things', 'day', 'going', 'don', 'employees', 'love', 'want', 'mind', 'girl', 'blowing', 'exist', 'new', 'really', 'account']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #11\n",
      "['trump', 'donald', 'clinton', 'president', 'hillary', 'win', 'think', 'election', 'better', '2016', 'presidential', 'happen', 'vote', 'presidency', 'students']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #12\n",
      "['life', 'work', 'real', 'purpose', 'thing', 'important', 'balance', 'differ', 'positions', 'departments', 'meaning', 'employees', 'live', 'want', 'change']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #13\n",
      "['way', 'weight', 'easiest', 'lose', 'suicide', 'fastest', 'commit', 'painless', 'gain', 'increase', 'account', 'prepare', 'facebook', 'instagram', 'quickest']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #14\n",
      "['time', 'possible', 'travel', 'sex', 'home', 'long', 'love', 'job', 'person', 'foreign', 'bring', 'feel', 'visitors', 'gifts', 'visitor']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #15\n",
      "['difference', 'engineering', 'computer', 'science', 'love', 'data', 'indian', 'better', 'software', 'use', 'company', 'account', 'job', 'non', 'programming']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #16\n",
      "['learn', 'language', 'programming', 'english', 'start', 'want', 'improve', 'learning', 'use', 'java', 'languages', 'python', 'online', 'skills', 'speak']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #17\n",
      "['math', 'frac', 'sqrt', 'value', 'sin', 'number', 'use', 'solve', 'cos', '2x', '12', 'dx', 'equation', 'right', 'tan']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #18\n",
      "['new', 'year', 'old', '2017', 'majors', 'going', 'looking', 'universities', 'day', 'recruit', 'grads', 'employees', 'start', 'things', 'job']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #19\n",
      "['money', 'online', 'earn', 'black', 'ways', 'account', 'youtube', 'bank', 'help', 'free', 'easy', 'home', 'start', 'making', 'facebook']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ERROR: This is based on nmf_model.fit(dtm), which is the wrong dtm\n",
    "\n",
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[::-1][:15]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:315: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  \"'nndsvda' in 1.1 (renaming of 0.26).\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['best', 'movies', 'books', 'book', '2016', 'ways', 'movie', 'laptop', 'buy', 'phone', 'places', 'visit', 'place', 'read', 'thing']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['does', 'mean', 'work', 'feel', 'long', 'cost', 'compare', 'really', 'exist', 'use', 'differ', 'looking', 'recruit', 'sex', 'grads']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['quora', 'questions', 'question', 'ask', 'answer', 'answers', 'google', 'asked', 'delete', 'improvement', 'easily', 'post', 'needing', 'answered', 'add']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['money', 'make', 'online', 'earn', 'ways', 'youtube', 'easy', 'home', 'free', 'internet', 'black', 'friends', 'com', 'investment', 'website']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['life', 'purpose', 'meaning', 'thing', 'important', 'real', 'moment', 'want', 'change', 'live', 'changed', 'death', 'day', 'earth', 'balance']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['india', 'pakistan', 'war', 'spotify', 'job', 'business', 'available', 'olympics', 'country', 'start', 'china', 'company', 'engineering', 'minister', 'president']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['people', 'think', 'don', 'ask', 'believe', 'hate', 'questions', 'flat', 'google', 'mind', 'use', 'easily', 'stop', 'blowing', 'earth']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['trump', 'donald', 'clinton', 'president', 'hillary', 'win', 'did', 'election', 'better', 'vote', '2016', 'presidential', 'think', 'presidency', 'happen']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['learn', 'language', 'programming', 'start', 'learning', 'java', 'languages', 'python', 'want', 'did', 'hacking', 'book', 'online', 'computer', 'beginners']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['like', 'feel', 'sex', 'look', 'girl', 'work', 'live', 'girls', 'women', 'culture', 'men', 'guy', 'companies', 'don', 'indian']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #10\n",
      "['good', 'books', 'bad', 'ways', 'engineering', 'work', 'job', 'start', 'read', 'business', 'songs', 'movies', 'provider', 'ca', 'solar']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #11\n",
      "['500', 'notes', '1000', 'rs', 'rupee', 'indian', 'black', 'banning', 'ban', 'think', 'government', 'economy', 'currency', 'modi', 'money']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #12\n",
      "['know', 'new', 'things', 'day', 'going', 'employees', 'don', 'year', '2017', 'girl', 'likes', 'mind', 'resolution', 'resolutions', 'blowing']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #13\n",
      "['english', 'improve', 'skills', 'writing', 'speaking', 'pronunciation', 'speak', 'communication', 'fluently', 'language', 'ways', 'spoken', 'skill', 'fluent', 'aspects']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #14\n",
      "['weight', 'lose', 'gain', 'ways', 'fat', 'fast', 'loss', 'quickly', 'reduce', 'pounds', 'month', 'exercise', 'healthy', 'help', 'diet']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #15\n",
      "['time', 'travel', 'possible', 'sex', 'home', 'job', 'favorite', 'movies', 'machine', 'person', 'did', 'spend', 'long', 'feel', 'having']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #16\n",
      "['love', 'fall', 'girl', 'person', 'know', 'true', 'friend', 'really', 'forget', 'tell', 'feel', 'girlfriend', 'did', 'make', 'marriage']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #17\n",
      "['difference', 'engineering', 'computer', 'science', 'software', 'data', 'use', 'job', 'account', 'better', 'java', 'scripting', 'chinese', 'web', 'mechanical']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #18\n",
      "['way', 'easiest', 'suicide', 'fastest', 'commit', 'best', 'account', 'instagram', 'painless', 'increase', 'facebook', 'quickest', 'prepare', 'hack', 'rid']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #19\n",
      "['world', 'war', 'did', 'iii', 'country', 'start', 'end', 'happen', 'pakistan', 'place', 'countries', 'coming', 'win', 'russia', 'live']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmf_model2 = NMF(n_components=20,random_state=42)\n",
    "nmf_model2.fit(dtm3)\n",
    "for index,topic in enumerate(nmf_model2.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf2.get_feature_names()[i] for i in topic.argsort()[::-1][:15]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404289, 20)\n",
      "                                             Question  Topic\n",
      "0   What is the step by step guide to invest in sh...      5\n",
      "1   What is the story of Kohinoor (Koh-i-Noor) Dia...     16\n",
      "2   How can I increase the speed of my internet co...     18\n",
      "3   Why am I mentally very lonely? How can I solve...     11\n",
      "4   Which one dissolve in water quikly sugar, salt...     14\n",
      "5   Astrology: I am a Capricorn Sun Cap moon and c...      1\n",
      "6                                 Should I buy tiago?      0\n",
      "7                      How can I be a good geologist?     10\n",
      "8                     When do you use シ instead of し?      2\n",
      "9   Motorola (company): Can I hack my Charter Moto...     18\n",
      "10  Method to find separation of slits using fresn...      2\n",
      "11        How do I read and find my YouTube comments?      3\n",
      "12               What can make Physics easy to learn?      8\n",
      "13        What was your first sexual experience like?      9\n",
      "14  What are the laws to change your status from a...      1\n",
      "15  What would a Trump presidency mean for current...      7\n",
      "16                       What does manipulation mean?      1\n",
      "17  Why do girls want to be friends with the guy t...      9\n",
      "18  Why are so many Quora users posting questions ...      2\n",
      "19  Which is the best digital marketing institutio...      0\n"
     ]
    }
   ],
   "source": [
    "topic_results2 = nmf_model2.transform(dtm3)\n",
    "print(topic_results2.shape)\n",
    "npr3 = npr\n",
    "npr3['Topic'] = topic_results2.argmax(axis=1)\n",
    "print(npr.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=20, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK: Print our the top 15 most common words for each of the 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['thing', 'read', 'place', 'visit', 'places', 'phone', 'buy', 'laptop', 'movie', 'ways', '2016', 'books', 'book', 'movies', 'best']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['majors', 'recruit', 'sex', 'looking', 'differ', 'use', 'exist', 'really', 'compare', 'cost', 'long', 'feel', 'work', 'mean', 'does']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['add', 'answered', 'needing', 'post', 'easily', 'improvement', 'delete', 'asked', 'google', 'answers', 'answer', 'ask', 'question', 'questions', 'quora']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['using', 'website', 'investment', 'friends', 'black', 'internet', 'free', 'home', 'easy', 'youtube', 'ways', 'earn', 'online', 'make', 'money']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['balance', 'earth', 'day', 'death', 'changed', 'live', 'want', 'change', 'moment', 'real', 'important', 'thing', 'meaning', 'purpose', 'life']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #5\n",
      "['reservation', 'engineering', 'minister', 'president', 'company', 'china', 'business', 'country', 'olympics', 'available', 'job', 'spotify', 'war', 'pakistan', 'india']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #6\n",
      "['beginners', 'online', 'english', 'book', 'did', 'hacking', 'want', 'python', 'languages', 'java', 'learning', 'start', 'language', 'programming', 'learn']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #7\n",
      "['happen', 'presidency', 'think', 'presidential', '2016', 'vote', 'better', 'election', 'did', 'win', 'hillary', 'president', 'clinton', 'donald', 'trump']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #8\n",
      "['russia', 'business', 'win', 'coming', 'countries', 'place', 'pakistan', 'happen', 'end', 'country', 'iii', 'start', 'did', 'war', 'world']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #9\n",
      "['indian', 'companies', 'don', 'guy', 'men', 'culture', 'women', 'work', 'girls', 'live', 'girl', 'look', 'sex', 'feel', 'like']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #10\n",
      "['ca', 'departments', 'positions', 'movies', 'songs', 'business', 'read', 'start', 'job', 'work', 'engineering', 'ways', 'bad', 'books', 'good']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #11\n",
      "['money', 'modi', 'currency', 'economy', 'think', 'government', 'ban', 'banning', 'black', 'indian', 'rupee', 'rs', '1000', 'notes', '500']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #12\n",
      "['blowing', 'resolutions', 'resolution', 'mind', 'likes', 'girl', '2017', 'year', 'don', 'employees', 'going', 'day', 'things', 'new', 'know']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #13\n",
      "['aspects', 'fluent', 'skill', 'spoken', 'ways', 'language', 'fluently', 'speak', 'communication', 'pronunciation', 'speaking', 'writing', 'skills', 'improve', 'english']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #14\n",
      "['diet', 'help', 'healthy', 'exercise', 'month', 'pounds', 'reduce', 'quickly', 'loss', 'fast', 'fat', 'ways', 'gain', 'lose', 'weight']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #15\n",
      "['having', 'feel', 'long', 'spend', 'did', 'person', 'machine', 'movies', 'favorite', 'job', 'home', 'sex', 'possible', 'travel', 'time']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #16\n",
      "['marriage', 'make', 'did', 'girlfriend', 'feel', 'tell', 'forget', 'really', 'friend', 'true', 'know', 'person', 'girl', 'fall', 'love']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #17\n",
      "['easy', 'hack', 'prepare', 'quickest', 'facebook', 'increase', 'painless', 'instagram', 'account', 'best', 'commit', 'fastest', 'suicide', 'easiest', 'way']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #18\n",
      "['web', 'java', 'scripting', 'phone', 'mechanical', 'better', 'job', 'use', 'account', 'data', 'software', 'science', 'computer', 'engineering', 'difference']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #19\n",
      "['earth', 'blowing', 'stop', 'use', 'easily', 'mind', 'google', 'flat', 'questions', 'hate', 'believe', 'ask', 'don', 'think', 'people']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK: Add a new column to the original quora dataframe that labels each question into one of the 20 topic categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Topic\n",
       "0  What is the step by step guide to invest in sh...      5\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...     16\n",
       "2  How can I increase the speed of my internet co...     17\n",
       "3  Why am I mentally very lonely? How can I solve...     11\n",
       "4  Which one dissolve in water quikly sugar, salt...     14\n",
       "5  Astrology: I am a Capricorn Sun Cap moon and c...      1\n",
       "6                                Should I buy tiago?      0\n",
       "7                     How can I be a good geologist?     10\n",
       "8                    When do you use シ instead of し?     19\n",
       "9  Motorola (company): Can I hack my Charter Moto...     17"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
